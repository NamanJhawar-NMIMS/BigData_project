{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Advanced Big Data Analytics Project - Mid term",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NamanJhawar-NMIMS/BigData_project/blob/main/Advanced_Big_Data_Analytics_Project_Mid_term.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Advanced Big Data Analytics - MID TERM assignment.**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z6T86UFEj8DH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare necessary Installations."
      ],
      "metadata": {
        "id": "St1aB2KdkNso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Beesxv5fmd3M",
        "outputId": "e9d65ebe-f52a-4b70-8479-c56cd49e5461"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 36 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 49.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=d4002f9a7aa22fdc5c83ec2bfdbe537037452ec6af91d4980403972f8227081b\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s3oRUc0vNUe",
        "outputId": "0d9ace52-2dc0-48c0-b9e4-b9f99c505353"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=adadc1abf922f84d5a6725b1adf6e776c598fd7f2f032fccb3679524ab077032\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "import all the necessary packages"
      ],
      "metadata": {
        "id": "XfddffmZvMkM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kRgta9iYlS1j"
      },
      "outputs": [],
      "source": [
        "import pyspark\n",
        "import os\n",
        "import wget\n",
        "from zipfile import ZipFile\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql.session import SparkContext, SparkSession\n",
        "\n",
        "from pyspark.sql.types import StringType,DateType\n",
        "from pyspark.sql.functions import udf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract the data from the Github repository"
      ],
      "metadata": {
        "id": "24XbkL8fkZNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download files from repository. This contains 14 files and 2nd wget file is a correction file.\n",
        "wget.download('https://github.com/NamanJhawar-NMIMS/BigData_project/raw/main/BigData_mart_data.zip', 'datafiles.zip')\n",
        "# Extracting the contents from the zip file in a new directory\n",
        "with ZipFile('datafiles.zip','r') as file:\n",
        "  file.extractall('datafiles_dir')\n",
        "\n",
        "time.sleep(5) #sleep added so as to make sure the autorefresh in collab has taken place to reflect the folder\n",
        "wget.download('https://raw.githubusercontent.com/NamanJhawar-NMIMS/BigData_project/main/productbatch.csv','datafiles_dir/productbatch.csv')"
      ],
      "metadata": {
        "id": "WdGB9OaAoWex",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c8eb231a-b8fa-4bd6-9b6c-edaa41728690"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'datafiles_dir/productbatch (1).csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correct filenames and delete incorrect files"
      ],
      "metadata": {
        "id": "hGJVHaLTkhP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#After importing the data, remove old productbatch.csv and rename the new file.\n",
        "os.remove('datafiles_dir/productbatch.csv')\n",
        "os.rename('datafiles_dir/productbatch (1).csv','datafiles_dir/productbatch.csv')"
      ],
      "metadata": {
        "id": "2Gz5Lf8CvkJH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the spark Context "
      ],
      "metadata": {
        "id": "FwFEF1o0kk4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a spark object\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  conf=SparkConf().setAppName('MidTermAssignment_project').setMaster('local')\n",
        "  sc=SparkContext(conf=conf)"
      ],
      "metadata": {
        "id": "cflysf0F10Cw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Resilient Distributed Dataset (RDD)**"
      ],
      "metadata": {
        "id": "Q4lEXWu0mM5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a RDD directly from CSV file using TextFile; Resilient Distributed Dataset\n",
        "\n",
        "branch_rdd=sc.textFile('datafiles_dir/branch.csv')\n",
        "rewards_rdd=sc.textFile('datafiles_dir/rewards.csv')\n",
        "product_rdd=sc.textFile('datafiles_dir/product.csv')"
      ],
      "metadata": {
        "id": "jnYf0e_1w0Lh"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying the type of variable\n",
        "\n",
        "print('Type:', type(branch_rdd))"
      ],
      "metadata": {
        "id": "Mj9mDHe7w0Qs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "529ce195-7174-4cfb-e9dc-67fc54713c60"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: <class 'pyspark.rdd.RDD'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count action helps to count number of rows in RDD\n",
        "\n",
        "print('Number of rows:', branch_rdd.count())"
      ],
      "metadata": {
        "id": "lJnYQ58rw0Ta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18de8b01-0a9b-458f-85f4-137277d1d084"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#First action displays the first row\n",
        "\n",
        "print('first row of RDD:\\n', branch_rdd.first())"
      ],
      "metadata": {
        "id": "o-zr-lrDw0V3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06e4afb5-5dd0-41da-9684-bad0be98cfe7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first row of RDD:\n",
            " BranchID,BranchName,AddressLine1,AddressLine2,City,Country,PinCode,PhoneNumber,emailID,createdatetime,updatedatetime\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take action displays the specified number of elements from an RDD\n",
        "\n",
        "print('First 2 rows of RDD :\\n', branch_rdd.take(2))"
      ],
      "metadata": {
        "id": "dD_SxR5V3tXl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa49401d-3b66-4811-96fc-6d6420b74ac0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 2 rows of RDD :\n",
            " ['BranchID,BranchName,AddressLine1,AddressLine2,City,Country,PinCode,PhoneNumber,emailID,createdatetime,updatedatetime', 'BCH0000001,Airoli,Dmart Road,\"Sector 10A, Airoli\",Mumbai,India,400708,9830022519,airoli@dmart.com,27-11-21 12:31,27-11-21 12:31']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Top Action for fetching rows on sorted basis\n",
        "\n",
        "print('Sorted 2 rows of RDD :\\n', branch_rdd.top(2))"
      ],
      "metadata": {
        "id": "g9iwnPPO3tad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22ffdf51-8b80-4f60-ec4a-26e2abb0f021"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorted 2 rows of RDD :\n",
            " ['BranchID,BranchName,AddressLine1,AddressLine2,City,Country,PinCode,PhoneNumber,emailID,createdatetime,updatedatetime', 'BCH0000010,Tilak,Swagath Mall,Tilak Nagar,Bengaluru,India,560011,9960078601,tilaknagar@dmart.com,27-11-21 13:09,27-11-21 13:09']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saveasTextFile is used to write on distributed storage system (HDFS or local system)\n",
        "\n",
        "branch_rdd.saveAsTextFile('branch_rdd.csv')\n",
        "print('File saved')"
      ],
      "metadata": {
        "id": "vKhVIgMc3tdF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb15beac-9453-4856-8d7c-16c4f0a7b3e9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Map transformation to split dataset and collect will display the\n",
        "\n",
        "symbols=branch_rdd.map(lambda x:x.split(' ')[0])\n",
        "print(symbols.collect())"
      ],
      "metadata": {
        "id": "xqT2aqc43tfi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca166af0-d448-4f86-ffce-870d14ac1e1e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['BranchID,BranchName,AddressLine1,AddressLine2,City,Country,PinCode,PhoneNumber,emailID,createdatetime,updatedatetime', 'BCH0000001,Airoli,Dmart', 'BCH0000002,GT', 'BCH0000003,Balanagar,Medak', 'BCH0000004,Metro', 'BCH0000005,Antrix,Dmart', 'BCH0000006,Jadavpur,Mauza', 'BCH0000007,AMR', 'BCH0000008,Kandivali,Mahavir', 'BCH0000009,Sanath,277', 'BCH0000010,Tilak,Swagath']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect function to showcase all the values\n",
        "branch_rdd.collect()"
      ],
      "metadata": {
        "id": "sXTxhXQN3tiT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35acd41f-b541-41b4-9f60-10faf98ea305"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BranchID,BranchName,AddressLine1,AddressLine2,City,Country,PinCode,PhoneNumber,emailID,createdatetime,updatedatetime',\n",
              " 'BCH0000001,Airoli,Dmart Road,\"Sector 10A, Airoli\",Mumbai,India,400708,9830022519,airoli@dmart.com,27-11-21 12:31,27-11-21 12:31',\n",
              " 'BCH0000002,GT Road,GT Road,Nehru Nagar III,Ghaziabad,India,201001,8695526985,chaudharymall@dmart.com,27-11-21 13:09,27-11-21 13:09',\n",
              " 'BCH0000003,Balanagar,Medak - Hyderabad Rd,Balanagar,Hyderabad,India,500037,7005269854,balanagar@dmart.com,27-11-21 13:09,27-11-21 13:09',\n",
              " 'BCH0000004,Metro Mall,Rajeswari Colony,Virugambakkam,Chennai,India,600092,7484335870,chandrametromall@dmart.com,27-11-21 13:09,27-11-21 13:09',\n",
              " 'BCH0000005,Antrix,Dmart Chokdi,Nikol,Ahmedabad,India,380038,9985745007,antrixarcade@dmart.com,27-11-21 13:09,27-11-21 13:09',\n",
              " 'BCH0000006,Jadavpur,Mauza Barakholla,Jadavpur,Kolkata,India,700099,9073677847,jadavpur@dmart.com,27-11-21 13:09,27-11-21 13:09',\n",
              " 'BCH0000007,AMR Park,AMR Business Park,Hongasandra,Bengaluru,India,560068,8025742644,hongasandra@dmart.com,27-11-21 13:09,27-11-21 13:09',\n",
              " 'BCH0000008,Kandivali,Mahavir Nagar,Kandivali,Mumbai,India,400067,9830024789,kandivali@dmart.com,27-11-21 13:09,27-11-21 13:09',\n",
              " 'BCH0000009,Sanath,277 Main Rd,Sanath Nagar,Hyderabad,India,500018,9005987456,sanathnagar@dmart.com,27-11-21 13:09,27-11-21 13:09',\n",
              " 'BCH0000010,Tilak,Swagath Mall,Tilak Nagar,Bengaluru,India,560011,9960078601,tilaknagar@dmart.com,27-11-21 13:09,27-11-21 13:09']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# take, top, first functions difference\n",
        "\n",
        "# take returns the values in the same sequence as it was in the RDD\n",
        "# top returns the values post sorting into descending order\n",
        "# first returns the first value in the RDD\n",
        "\n",
        "take_rdd = sc.parallelize([1,2222,3,4,5])\n",
        "print(take_rdd.take(3))\n",
        "print(take_rdd.top(4))\n",
        "print(take_rdd.first())"
      ],
      "metadata": {
        "id": "okckOVq63tk8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe8772ae-0410-4840-a404-437dcb89cca6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2222, 3]\n",
            "[2222, 5, 4, 3]\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the updatedatetime column using the Map function \n",
        "updatedatetime_list=branch_rdd.map(lambda x:x.split(',')[10])\n",
        "updatedatetime_list.collect()"
      ],
      "metadata": {
        "id": "2iHnX_Mq3tnw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9cc50a2-f0c3-4d75-aac4-93f28009a652"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['updatedatetime',\n",
              " '27-11-21 12:31',\n",
              " '27-11-21 13:09',\n",
              " '27-11-21 13:09',\n",
              " '27-11-21 13:09',\n",
              " '27-11-21 13:09',\n",
              " '27-11-21 13:09',\n",
              " '27-11-21 13:09',\n",
              " '27-11-21 13:09',\n",
              " '27-11-21 13:09',\n",
              " '27-11-21 13:09']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce RDD\n",
        "def splitFunction(x):\n",
        "  x=x.split(',')[1]\n",
        "  if x.isnumeric():\n",
        "    return int(x)\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "totalRewardsEarned=rewards_rdd.map(splitFunction)\n",
        "print(totalRewardsEarned.collect())\n",
        "print('Total reward earned till date:',totalRewardsEarned.reduce(lambda x,y:int(x)+int(y)))"
      ],
      "metadata": {
        "id": "pZHB6G0_IPZz",
        "outputId": "993cc7e5-2662-49d8-82ff-b6187c37b2a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 820, 852, 1870, 1856, 8, 1365, 261, 782, 1729, 647, 1094, 346, 864, 1066, 767, 1163, 1895, 815, 1581, 766, 301, 389, 1153, 1436, 1044, 850, 1611, 1269, 192, 617, 1633, 439, 1952, 1905, 1263, 1505, 754, 1075, 1244, 769, 449, 1230, 1583, 644, 1143, 1412, 540, 696, 595, 1863, 1222, 1029, 1109, 1611, 1122, 562, 424, 903, 1998, 1665, 407, 850, 114, 162, 1637, 599, 718, 682, 33, 1708, 1934, 225, 1523, 551, 1184, 939, 172, 561, 127, 329, 1119]\n",
            "Total reward earned till date: 79322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use filter in RDD\n",
        "# find the row for a specific customer\n",
        "input_filtered=rewards_rdd.filter(lambda row : \n",
        "                                  (row.split(\",\")[0]==\"CUS0000160\"))\n",
        "print(input_filtered.count(), input_filtered.collect())"
      ],
      "metadata": {
        "id": "bEjEP5PTM3PO",
        "outputId": "ccc1bf8d-a3af-4a23-eecf-b4e18ac0490d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 ['CUS0000160,820,795,29-11-21 12:00,29-11-21 12:00']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use filter in RDD\n",
        "filter_rdd_2 = sc.parallelize(['Rahul', 'Swati', 'Rohan', 'Shreya', 'Priya'])\n",
        "print(filter_rdd_2.filter(lambda x: x.startswith('R')).collect())\n"
      ],
      "metadata": {
        "id": "zOAkAvrsBBrJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69fd95c2-d2e2-489d-c6f9-aeb7306c9958"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Rahul', 'Rohan']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# union function to join 2 rdd outputs\n",
        "union_rdd_1 = union_inp.filter(lambda x: x % 2 == 0)\n",
        "union_rdd_2 = union_inp.filter(lambda x: x % 3 == 0)\n",
        "print(union_rdd_1.union(union_rdd_2).collect())"
      ],
      "metadata": {
        "id": "7RMKLboPB0HU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ee59992-565b-4fc5-cc90-2ae7b571bd16"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 4, 6, 8, 6, 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# flatmap"
      ],
      "metadata": {
        "id": "nL_t1LSdOjYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# flatmap\n",
        "\n",
        "flatmap_rdd = sc.parallelize([\"Hey there\", \"This is PySpark RDD Transformations\"])\n",
        "(flatmap_rdd.flatMap(lambda x: x.split(\" \")).collect())"
      ],
      "metadata": {
        "id": "GnbG__MBlOv0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa6cd594-31ed-49be-ef53-7452090b746a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hey', 'there', 'This', 'is', 'PySpark', 'RDD', 'Transformations']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# paired RDD\n",
        "\n",
        "marks = [('Rahul', 88), ('Swati', 92), ('Shreya', 83), ('Abhay', 93), ('Rohan', 78)]\n",
        "sc.parallelize(marks).collect()"
      ],
      "metadata": {
        "id": "MleTFVeQB0eq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "117c8fc4-f3bc-418d-cca7-d65dbb4de1c2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Rahul', 88), ('Swati', 92), ('Shreya', 83), ('Abhay', 93), ('Rohan', 78)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce by Key function in RDD\n",
        "\n",
        "marks_rdd = sc.parallelize([('Rahul', 25), ('Swati', 26), ('Shreya', 22), ('Abhay', 29), ('Rohan', 22), ('Rahul', 23), ('Swati', 19), ('Shreya', 28), ('Abhay', 26), ('Rohan', 22)])\n",
        "print(marks_rdd.reduceByKey(lambda x, y: x + y).collect())"
      ],
      "metadata": {
        "id": "xAkzZ4DvloRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sort by key \n",
        "marks_rdd = sc.parallelize([('Rahul', 25), ('Swati', 26), \n",
        "                            ('Shreya', 22), ('Abhay', 29), \n",
        "                            ('Rohan', 22), ('Rahul', 23), \n",
        "                            ('Swati', 19), ('Shreya', 28), \n",
        "                            ('Abhay', 26), ('Rohan', 22)])\n",
        "\n",
        "print(marks_rdd.sortByKey('ascending').collect())"
      ],
      "metadata": {
        "id": "yD553IE5loO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# group by key\n",
        "\n",
        "marks_rdd = sc.parallelize([('Rahul', 25), ('Swati', 26), \n",
        "                            ('Shreya', 22), ('Abhay', 29), ('Rohan', 22), \n",
        "                            ('Rahul', 23), ('Swati', 19), ('Shreya', 28), \n",
        "                            ('Abhay', 26), ('Rohan', 22)])\n",
        "dict_rdd = marks_rdd.groupByKey().collect()\n",
        "for key, value in dict_rdd:\n",
        "    print(key, list(value))"
      ],
      "metadata": {
        "id": "8VP56FB6loL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count by key \n",
        "\n",
        "marks_rdd = sc.parallelize([('Rahul', 25), ('Swati', 26), ('Rohan', 22), \n",
        "                            ('Rahul', 23), ('Swati', 19), ('Shreya', 28), \n",
        "                            ('Abhay', 26), ('Rohan', 22)])\n",
        "dict_rdd = marks_rdd.countByKey().items()\n",
        "for key, value in dict_rdd:\n",
        "    print(key, value)"
      ],
      "metadata": {
        "id": "lo3-Rj-IloJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dataframes in pyspark**"
      ],
      "metadata": {
        "id": "gh_DHtU6mWF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session=SparkSession.builder.appName(\"NewApplication_midterm_dataframes\").master('local').getOrCreate()"
      ],
      "metadata": {
        "id": "OlZb75pPnxsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dynamically load all the csv files into pyspark object\n",
        "# using this we have dynamically created objects. \n",
        "path='datafiles_dir'\n",
        "dataframe_file_dict={} # The key of this dictionary will act as an object to a pyspark dataframe\n",
        "for file in os.listdir(path):\n",
        "  dataframe_file_dict[file]=session.read.csv(f'{path}/{file}',inferSchema=True,header=True)\n",
        "  #object=session.read.csv(filename)\n"
      ],
      "metadata": {
        "id": "Mu3Ow55_loE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confirm the datatype of the dynamically created object\n",
        "type(dataframe_file_dict['branch.csv'])"
      ],
      "metadata": {
        "id": "dQ9mXXKGpkAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show function is used to print the dataframe on the screen\n",
        "dataframe_file_dict['branch.csv'].show()"
      ],
      "metadata": {
        "id": "rPq8-cb4loCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print schema is used to show the data type \n",
        "dataframe_file_dict['branch.csv'].printSchema()"
      ],
      "metadata": {
        "id": "ayaoZLpuln9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # columns function is used to print the columns that are there for a particular dataframe\n",
        "  dataframe_file_dict['branch.csv'].columns"
      ],
      "metadata": {
        "id": "pUZfZLt0ln0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # dtype function is used to print a list of tuples the columns and their corresponding type\n",
        "  # that are there for a particular dataframe\n",
        "  dataframe_file_dict['branch.csv'].dtypes"
      ],
      "metadata": {
        "id": "HSHoEStDo6ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert all the objects into tempView tables "
      ],
      "metadata": {
        "id": "yuiqFg56pz-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create tempViews for all the dataframes and name them 'objectName_tdb'\n",
        "for dataframe_object in list(dataframe_file_dict.keys()):\n",
        "  dataframe_file_dict[dataframe_object].createOrReplaceTempView(f\"{dataframe_object.split('.')[0]}_tdb\")\n"
      ],
      "metadata": {
        "id": "EoabzaGBo6lG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if the tempviews were created sucessfully\n",
        "from pyspark import SparkContext \n",
        "from pyspark.sql import SQLContext \n",
        "sqlc = SQLContext(sc)\n",
        "\n",
        "for tempView in sqlc.tableNames():\n",
        "  print(tempView)"
      ],
      "metadata": {
        "id": "A2HG8F72o6jI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using these tables, let's create queries"
      ],
      "metadata": {
        "id": "asbL_xgosYMW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query 1: As an Inventory manager you want to look at which stock is closest to get over so that you can plan to order it immediately. Find the \n",
        "stock which is there the least.\n",
        "Also find the supplier and their contact info."
      ],
      "metadata": {
        "id": "Vfq-FZvktX4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session.sql('''select p.productid,p.productname, Available, Quantity, Price,p.SupplierID,s.SupplierName,s.PhoneNumber \n",
        "from product_tdb p, supplier_tdb s \n",
        "where p.SupplierID=s.SupplierID and p.Available='N' \n",
        "and p.Quantity=(select min(Quantity) from product_tdb) \n",
        "order by s.supplierid''').show()\n"
      ],
      "metadata": {
        "id": "HE1qeiT0o6eM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query 2: Which is the highest selling product in dmart."
      ],
      "metadata": {
        "id": "fUbNKrnetpHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session.sql('''\n",
        "Select P.ProductName, sum(O.quantity) from orderitem_tdb O inner join product_tdb P on P.productid=O.productid group by P.ProductName order \n",
        "by 2 desc limit 1;\n",
        "''').show()"
      ],
      "metadata": {
        "id": "8EO9wTo8o6bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query 3**: Find how many items the customers have shopped with us"
      ],
      "metadata": {
        "id": "uIFZXcM9uC8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session.sql('''\n",
        "select customerid, count(customerid) \n",
        "from order_tdb \n",
        "group by CustomerID \n",
        "having count(customerid) >2 \n",
        "order by 2 desc\n",
        "'''.replace('\\n',' ')).show()"
      ],
      "metadata": {
        "id": "f0X_Eh1JuEBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query 4**: What is the average bill of a customer?\n"
      ],
      "metadata": {
        "id": "EMu51TQXu62C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session.sql(\"\"\"\n",
        "SELECT ROUND(AVG(ordertotal), 2) as Customer_Average_Bill FROM order_tdb;\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "JlbQYXPNu6sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query 5**: Top 5 Spenders"
      ],
      "metadata": {
        "id": "d4LwQ8bNvdtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session.sql(\"\"\"\n",
        "SELECT C.Customerid,CONCAT(C.FirstName, ' ',C.LastName) as FullName,\n",
        " C.MobileNumber,ROUND(AVG(O.ordertotal), 2) as average_spend\n",
        "FROM order_tdb O, customer_tdb C \n",
        "WHERE O.customerid = C.customerid \n",
        "GROUP BY C.customerid, CONCAT(C.FirstName, ' ',C.LastName),C.MobileNumber \n",
        "ORDER BY AVG(O.OrderTotal) DESC \n",
        "LIMIT 5\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "pvwd8RqJu6qM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query 6**: As an inventory manager you want to understand how many products do we have for each product category.\n"
      ],
      "metadata": {
        "id": "bgp11DCpvwN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session.sql(\"\"\"\n",
        "Select p.Categoryid, pc.categorytype, COUNT(p.categoryID) \n",
        "FROM product_tdb p, product_category_tdb pc \n",
        "WHERE p.categoryID=pc.CategoryID \n",
        "GROUP BY p.CategoryID, pc.CategoryType \n",
        "ORDER BY COUNT(p.CategoryID) DESC;\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "ZyaPNMpku6ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query 7**: Products that are about to expire in the next 6 months and luxury\n"
      ],
      "metadata": {
        "id": "M6OfIPrYvv5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session.sql(\"\"\"\n",
        "SELECT P.productname, B.BrandName, B.BrandType, PB.expiryDate \n",
        "FROM productbatch_tdb PB, Product_tdb P, brand_tdb B \n",
        "WHERE PB.ProductID =P.Productid \n",
        " AND P.Brandid = B.Brandid \n",
        " AND PB.expiryDate > (current_date) \n",
        " AND PB.expiryDate < DATE_ADD((current_date), 180);\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "pRPYYp0Au6lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query 8**: As the manager you want to understand the generations from which your employees come. This would help you bring HR related \n",
        "changes in the future."
      ],
      "metadata": {
        "id": "87l_dfF0vvjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def str_to_date(dob):\n",
        "  return datetime.strptime(dob, '%d-%m-%y')\n",
        "\n",
        "session.udf.register(\"str_to_date_udf\", str_to_date,DateType())\n",
        "\n",
        "\n",
        "session.sql(\"\"\"\n",
        "SELECT CONCAT(Firstname, ' ', lastname) as FullName, str_to_date_udf(dob) as DOB ,\n",
        " CASE WHEN YEAR(str_to_date_udf(dob)) BETWEEN 1946 AND 1964 THEN 'Baby Boomers' \n",
        " WHEN YEAR(str_to_date_udf(dob)) BETWEEN 1965 AND 1980 THEN 'Gen X' \n",
        " WHEN YEAR(str_to_date_udf(dob)) BETWEEN 1981 AND 1996 THEN 'Millennial' \n",
        " ELSE 'Gen Z' END as Generation\n",
        "FROM employee_tdb\"\"\").show()"
      ],
      "metadata": {
        "id": "rryd2jJBu6i6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query 9**: Find the products that have been sold more than 50 quantities"
      ],
      "metadata": {
        "id": "ing1TkCCvvQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session.sql(\"\"\"\n",
        "SELECT P.productid, P.ProductName, SUM(OI.Quantity) AS QuantitySold \n",
        "FROM orderitem_tdb OI, product_tdb P \n",
        "WHERE P.productid = OI.productid \n",
        "GROUP BY P.productid,P.ProductName \n",
        "HAVING QuantitySold > 50 \n",
        "order by QuantitySold desc\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "f_KF9A2Du6gF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query 10**: How many brands are there for each brand type?\n"
      ],
      "metadata": {
        "id": "u6LD0vwYvu88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session.sql(\"\"\"\n",
        "SELECT brandtype, COUNT(*) as  quantity \n",
        "FROM Brand_tdb \n",
        "GROUP BY brandtype \n",
        "ORDER BY 2\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "kdDCjMzFu6dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query 11**: No of cities in which Dmart has branches\n"
      ],
      "metadata": {
        "id": "xowQJFk1vumg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session.sql(\"\"\"\n",
        "SELECT COUNT(DISTINCT city) as Number_of_Cities FROM branch_tdb\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "JSaXdFJru6bC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query 12**: What are the total payments done via different modes? The transactions need to be successful.\n"
      ],
      "metadata": {
        "id": "1QSvK7SxvuQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session.sql(\"\"\"\n",
        "select sum(amount), paymentmode from transaction_tdb where TransactionStatus='Success' group by PaymentMode order by 1 desc;\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "lTbgliwVu6RL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query 13**:What are the demographics of the customer base?\n"
      ],
      "metadata": {
        "id": "M3264Atsvt8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session.sql(\"\"\"\n",
        "select count(gender), gender from customer_tdb group by gender;\n",
        "\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "_RfTg45ro6Zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query 14**:The store wants to update all it’s Security Guards regarding an upcoming festival. We need their phone numbers to send them an sms regarding the same.\n"
      ],
      "metadata": {
        "id": "H794SAEvvtl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session.sql(\"\"\"\n",
        "select concat(e.firstname,e.lastname), e.mobilenumber, s.SkillName from employee_tdb e, skill_tdb s where e.skill_code=s.Skill_code and SkillName='Security';\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "KXslTZZ7o6W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query 15**:Select the Products that are not in the Luxury segment"
      ],
      "metadata": {
        "id": "Wlm7I8PjvtIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session.sql(\"\"\"\n",
        "SELECT\n",
        "\tP.ProductName, B.BrandName, B.BrandType\n",
        "FROM\n",
        "\tbrand_tdb B,\n",
        "\tproduct_tdb P\n",
        "WHERE\n",
        "\tB.BrandID = P.BrandID\n",
        "    \tAND B.BrandType != 'Luxury';\n",
        "\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "6fvlWi3lo6UM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query 16**:Customer who has earned the most reward points\n"
      ],
      "metadata": {
        "id": "8v31T4M_vsxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session.sql(\"\"\"\n",
        "SELECT CONCAT(C.Firstname, ' ', C.lastname),(R.TotalRewardPointsEarned + R.TotalRewardPointRedeemed) as totalPoints \n",
        "FROM customer_tdb C, rewards_tdb R \n",
        "WHERE C.customerid = R.customerid \n",
        "ORDER BY 2 DESC LIMIT 1\"\"\").show()"
      ],
      "metadata": {
        "id": "z9o83Rhhvp8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query 17**:The business wants to run a campaign to promote their Rewards program with their existing customers who are currently not part of the same.\n",
        "Find the list of Names and Mobile numbers so that you can run that campaign.alter\n"
      ],
      "metadata": {
        "id": "hQlErv0pvsSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session.sql(\"\"\"\n",
        "SELECT \n",
        "  S.Suppliername, S.PhoneNumber \n",
        "FROM \n",
        "  supplier_tdb S, Supplier_branch_relation_tdb SBR \n",
        "WHERE \n",
        "  SBR.supplierid = S.supplierid AND SBR.branchid \n",
        "IN \n",
        "  (SELECT branchid FROM branch_tdb WHERE city = 'Mumbai');\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "04uf1Hjkvp4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query 18**: Top 3 brands that have generated the highest revenue\n"
      ],
      "metadata": {
        "id": "dYZCWDkrvr8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session.sql(\"\"\"\n",
        "SELECT \n",
        "  B.brandname,B.brandtype, ROUND(SUM(OI.subtotal + OI.tax - OI.ItemDiscount),2)\n",
        "FROM \n",
        "  Brand_tdb B, Product_tdb P, Orderitem_tdb OI \n",
        "WHERE \n",
        "  B.brandid = P.brandid AND P.Productid = OI.productid\n",
        "GROUP BY \n",
        "  B.brandname, B.brandtype\n",
        "ORDER BY\n",
        "  3 DESC \n",
        "LIMIT 3;\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "wWtKec0xvp1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query 19**:Due to rising cases in the 4th wave, the Dmart stores in Mumbai are going to be closed for a few days. We need to inform the suppliers to defer the standing orders.Find the names and mobile number of the suppliers so that you can contact them.\n"
      ],
      "metadata": {
        "id": "ob-cCfhEvrop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session.sql(\"\"\"\n",
        "SELECT \n",
        "  S.Suppliername, S.PhoneNumber \n",
        "FROM \n",
        "  supplier_tdb S, Supplier_branch_relation_tdb SBR \n",
        "WHERE SBR.supplierid = S.supplierid \n",
        "AND \n",
        "  SBR.branchid \n",
        "IN \n",
        "  (SELECT branchid FROM branch_tdb WHERE city = 'Mumbai');\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "ddDJcyK1vpxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query 20**:Find the names and contact info of all employees who are managers and based in Mumbai as the company wants to provide instructions regarding an upcoming mega sale in the Mumbai stores.\n"
      ],
      "metadata": {
        "id": "f5ASqd9_vrWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session.sql(\"\"\"\n",
        "SELECT \n",
        "  firstname, lastname, MobileNumber, B.city \n",
        "FROM \n",
        "  employee_tdb E,Branch_tdb B \n",
        "WHERE \n",
        "  B.branchid = E.branchid AND B.city = 'Mumbai' AND E.skill_code \n",
        "IN \n",
        "  (SELECT skill_code FROM skill_tdb WHERE skillname LIKE '%Manager%')\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "QsjTBktTvpu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Column Transformations"
      ],
      "metadata": {
        "id": "tpMXQbNn1HnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe_file_dict['product.csv'].show(10)"
      ],
      "metadata": {
        "id": "qqgww2952fj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the quantity of products available\n",
        "dataframe_file_dict['product.csv'].select('ProductName','Quantity').show(5)"
      ],
      "metadata": {
        "id": "czVkGztA12OB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a User defined function and use this in SQL and column transformation to generate the fullname of the employee\n",
        "\n",
        "def fullName(firstname,lastname):\n",
        "  return firstname+\" \"+lastname\n",
        "\n",
        "session.udf.register(\"fullName_udf\", fullName,StringType())\n",
        "\n",
        "fullName_col_udf=udf(fullName,StringType())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9hU5qlew1HUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result=dataframe_file_dict['employee.csv'].withColumn('fullName',fullName_col_udf(\"FirstName\",\"LastName\"))\n",
        "result.select('EmployeeID','FirstName','lastname','Fullname').show(10)"
      ],
      "metadata": {
        "id": "KVuxeO28bO_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session.sql('select fullname_udf(firstname,lastname) FROM employee_tdb').show(5)"
      ],
      "metadata": {
        "id": "CnkMusP72LyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ban products using the utf column transformation\n",
        "ban_product='BRD0000006'\n",
        "def ban_products(BrandID):\n",
        "  if BrandID==ban_product:\n",
        "    return 'Y'\n",
        "  else:\n",
        "    return 'N'\n",
        "  \n",
        "ban_products_udf=udf(ban_products,StringType())\n",
        "\n",
        "result=dataframe_file_dict['product.csv'].withColumn('ban_status',ban_products_udf(dataframe_file_dict['product.csv'].BrandID))\n",
        "result.select('BrandID','ProductID','ProductName','Available','ban_status').show(10)"
      ],
      "metadata": {
        "id": "V8XJWUQNJjzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# return all those products which have been banned\n",
        "result.select('BrandID','ProductID','ProductName','Available','ban_status').where(result.ban_status=='Y').show()"
      ],
      "metadata": {
        "id": "34kNzi8qO82n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RKnHX1ZKjXPt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}